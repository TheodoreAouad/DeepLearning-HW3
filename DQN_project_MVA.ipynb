{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "S5VA7wAs-Y5N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "metadata": {
        "id": "pdsWJsc7-f7B",
        "colab_type": "code",
        "outputId": "53509a65-db3c-417c-e363-f77c0d49325b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install sk-video"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sk-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/3f/ce848b8b2062ad1ccf1449094a740c775f6c761339f411e44f1e090f23a7/sk_video-1.1.10-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.3MB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.14.6)\n",
            "Installing collected packages: sk-video\n",
            "Successfully installed sk-video-1.1.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8tNYr8Gb-Y5T",
        "colab_type": "code",
        "outputId": "cead6af2-b77e-4ad8-ccd6-6970a06d4f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "74aiCAQv-Y5e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MiniProject #3: Deep Reinforcement Learning"
      ]
    },
    {
      "metadata": {
        "id": "TgQIBf21-Y5h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "metadata": {
        "id": "KrRSIzGV-Y5l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Context"
      ]
    },
    {
      "metadata": {
        "id": "ZQhDp6o6-Y5n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "metadata": {
        "id": "4HsSiWND-Y5q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "metadata": {
        "id": "YIEr5wrd-Y5s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The environment"
      ]
    },
    {
      "metadata": {
        "id": "zZjdF9Cd-Y5v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "metadata": {
        "id": "WjnAWkN1-Y5y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOSyd4pB-Y56",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "metadata": {
        "id": "4rttRma8-Y58",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Agent"
      ]
    },
    {
      "metadata": {
        "id": "vMPEuL8X-Y5-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "metadata": {
        "id": "QOEE9kje-Y6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_2-x34We-Y6L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "metadata": {
        "id": "p12RAlRO-Y6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The act method of the Agent system performs the random policy with probability $\\epsilon$, and performs the learned policy with probability $1-\\epsilon$. The random policy part is essential to ensure an exploration part for the algorithm. The agent needs to explore its environment in order to discover the best actions to take. It cannot always take the best action it has learned up until now otherwise it will never learn new behaviors that could be better."
      ]
    },
    {
      "metadata": {
        "id": "GqiDbi1D-Y6O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "metadata": {
        "id": "K2bBQIVi-Y6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "gtNzmjbf-Y6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "metadata": {
        "id": "tylfZ8oz-Y6V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "metadata": {
        "id": "n3tzIiOU-Y6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kPvTpeED-Y6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "metadata": {
        "id": "SiU7VSJQ-Y6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=51 # set small when debugging\n",
        "epochs_test=10 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xlRM3P39-Y6m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "metadata": {
        "id": "ZtseZpVY-Y6o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The array \"position\" represents the previous position of the rat on the board, before taking the action. The \"board\" array represents the cells that contain cheese and the cells that contain poison."
      ]
    },
    {
      "metadata": {
        "id": "haiyiFeW-Y6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Agent"
      ]
    },
    {
      "metadata": {
        "id": "2rwEVt4e-Y6q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "metadata": {
        "id": "A-EKz8W3-Y6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.random.randint(0,4,size = 1)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ai7BtNkb-Y6w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "metadata": {
        "id": "W-MDK2ry-Y6y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    \n",
        "        \n",
        "    for e in range(epochs):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "    \n",
        "        win = 0\n",
        "        lose = 0\n",
        "    \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "glyjy_4T-Y62",
        "colab_type": "code",
        "outputId": "12acdd56-021e-4a63-c3ee-685da422a02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 17.0/17.0. Average score (0.0)\n",
            "Win/lose count 11.5/17.0. Average score (-2.75)\n",
            "Win/lose count 5.0/8.0. Average score (-2.8333333333333335)\n",
            "Win/lose count 11.0/9.0. Average score (-1.625)\n",
            "Win/lose count 7.0/16.0. Average score (-3.1)\n",
            "Win/lose count 5.0/5.0. Average score (-2.5833333333333335)\n",
            "Win/lose count 8.0/14.0. Average score (-3.0714285714285716)\n",
            "Win/lose count 13.0/18.0. Average score (-3.3125)\n",
            "Win/lose count 10.0/14.0. Average score (-3.388888888888889)\n",
            "Win/lose count 8.5/5.0. Average score (-2.7)\n",
            "Final score: -2.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "z8qCLoOg-Y69",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "metadata": {
        "id": "w2_nkFAN-Y6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zQZMQMDe-Y7A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1.\n",
        "\\begin{align*}Q^\\pi(s,a)&=E_{(s_0,a_0,s_1,a_1,...)}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\\\\n",
        "&= E_{(s_0,a_0,s_1,a_1,...)}[r(s,a) + \\gamma\\sum_{t\\leq T-1}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{0}=s,a_{0}=a] \\\\\n",
        "&= r(s,a) + \\gamma E_{(s_1,a_1,s_2,a_2,..)}[\\sum_{t\\leq T-1}\\gamma^{t}r(s_{t+1},a_{t+1})|s_{0}=s,a_{0}=a] \\\\\n",
        "&= r(s,a) + \\gamma E_{(s',a')}\\Big[E_{(s_2,a_2,s_2,a_3,..)}[\\sum_{t\\leq T-1}\\gamma^{t}r(s_{t+1},a_{t+1})|s_1 = s', a_1 = a', s_{0}=s,a_{0}=a]\\Big] \\\\\n",
        "&= r(s,a) + \\gamma E_{(s',a')}\\Big[E_{(s_2,a_2,s_2,a_3,..)}[\\sum_{t\\leq T-1}\\gamma^{t}r(s_{t+1},a_{t+1})|s_1 = s', a_1 = a']\\Big] \\\\\n",
        "&= r(s,a) + \\gamma E_{(s',a')}\\Big[Q^{\\pi}(s',a')\\Big]\n",
        "\\end{align*} \\\\\n",
        "\n",
        "2.\n",
        "\\begin{align*} Q^*(s,a) &= \\max_{\\pi}Q^{\\pi}(s,a) \\\\\n",
        "&=\\max_{\\pi}(r(s,a) + \\gamma E_{(s',a')}[Q^{\\pi}(s',a')]) \\\\\n",
        "&=  r(s,a) + \\gamma \\max_{\\pi}(E_{(s',a')}[Q^{\\pi}(s',a')]) \\\\\n",
        "\\end{align*}\n",
        "Let us show that \n",
        "\\begin{equation*} \\max_{\\pi}(E_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')])=E_{s'' \\sim \\pi^*(.|s,a)}[\\max_{a''}Q^*(s'',a'')]\n",
        "\\end{equation*}.\n",
        "\n",
        "\\begin{align*}  \\max_{\\pi}(E_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')]) &\\leq E_{s'' \\sim \\pi^*(.|s,a)}[\\max_{a''}\\max_{\\pi}Q^{\\pi}(s',a'')]\\\\\n",
        "&\\leq E_{s'' \\sim \\pi^*(.|s,a)}[\\max_{a''}Q^{*}(s',a'')]\n",
        "\\end{align*}\n",
        "\n",
        "\\begin{align*}E_{s'' \\sim \\pi^*(.|s,a)}[\\max_{a''}Q^*(s',a'')] &= \\max_{a''}(E_{s'' \\sim \\pi^*(.|s,a)}[Q^{\\pi^*}(s',a'')]) \\\\\n",
        "&\\leq \\max_{a''}\\max_{\\pi}E_{(s',a')\\sim p^{\\pi}(.|s,a)}[Q^{\\pi}(s',a')] \\\\\n",
        "&\\leq \\max_{\\pi}E_{(s',a')\\sim p^{\\pi}(.|s,a)}[Q^{\\pi}(s',a')] \n",
        "\\end{align*}\n",
        "\n",
        "This concludes the proof.\n",
        "\n",
        "3.\n",
        "We want to find the $Q$ function that is maximal according to the action $a$ to perform. Therefore, it makes sense to push our $Q$ function toward the maximum it is aiming to become. The first part $r+\\gamma\\max_{a'}Q(s',a',\\theta)$ represents the optimal $Q$ function, without the expectation. Hence why we want to make $Q$ closer to this expression."
      ]
    },
    {
      "metadata": {
        "id": "RwHrhqpe-Y7A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "metadata": {
        "id": "ne9lECr--Y7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        if len(self.memory) < self.max_memory:self.memory.append(m)\n",
        "        else: self.memory = self.memory[1:]+[m]\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(0,len(self.memory))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQs2ZpNy5_Dq",
        "colab_type": "code",
        "outputId": "71b00dd0-e9eb-4336-ce8d-a0931fd05797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "a = [0,2,1]\n",
        "a = a[1:] + [5]\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 1, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "metadata": {
        "id": "GWEidUXd-Y7E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "metadata": {
        "id": "Mo1eA0Lm-Y7E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        \n",
        "        \n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VH6ke2YV2zK8",
        "colab_type": "code",
        "outputId": "18ccb63d-51c3-4dfa-d03d-f8f8d92d72cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "None is None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "VItt4qQA-Y7H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "metadata": {
        "id": "leRrV6Qn-Y7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return self.model.predict(s.reshape(1,5,5,self.n_state)).argmax()\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "        \n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "\n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            \n",
        "            s,ns,a,r,go = self.memory.random_access()\n",
        "            s = s.reshape(1,5,5,self.n_state)\n",
        "            ns = ns.reshape(1,5,5,self.n_state)\n",
        "            input_states[i] = s\n",
        "            \n",
        "            if game_over_:\n",
        "                target_q[i] = self.model.predict(s)\n",
        "                target_q[i,a] = r\n",
        "            else:\n",
        "                target_q[i] = self.model.predict(s)\n",
        "                target_q[i,a] = r + self.discount*(self.model.predict(ns)).max()\n",
        "                \n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape = (5,5,self.n_state)))\n",
        "        model.add(Dense(16,activation = 'relu'))\n",
        "        model.add(Dense(4,activation = 'linear'))\n",
        "                    \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVXGdRmw-Y7K",
        "colab_type": "code",
        "outputId": "f260b6bc-a6b0-43d1-c478-1cbb2c25e2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "t1 = time.time()\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "print(\"Duration of training: \", time.time()-t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 000/051 | Loss 0.2445 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 001/051 | Loss 0.1582 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 002/051 | Loss 0.3288 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 003/051 | Loss 0.3226 | Win/lose count 4.5/6.0 (-1.5)\n",
            "Epoch 004/051 | Loss 0.4628 | Win/lose count 4.0/3.0 (1.0)\n",
            "Epoch 005/051 | Loss 0.5284 | Win/lose count 0/2.0 (-2.0)\n",
            "Epoch 006/051 | Loss 0.4810 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 007/051 | Loss 0.7841 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 008/051 | Loss 0.9620 | Win/lose count 5.0/8.0 (-3.0)\n",
            "Epoch 009/051 | Loss 1.4987 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 010/051 | Loss 1.5571 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 011/051 | Loss 1.7726 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 012/051 | Loss 1.8166 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 013/051 | Loss 1.8980 | Win/lose count 2.0/0 (2.0)\n",
            "Epoch 014/051 | Loss 1.7563 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 015/051 | Loss 1.8609 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 016/051 | Loss 1.7528 | Win/lose count 1.0/0 (1.0)\n",
            "Epoch 017/051 | Loss 1.6615 | Win/lose count 1.5/1.0 (0.5)\n",
            "Epoch 018/051 | Loss 1.5726 | Win/lose count 6.0/2.0 (4.0)\n",
            "Epoch 019/051 | Loss 1.6097 | Win/lose count 6.5/5.0 (1.5)\n",
            "Epoch 020/051 | Loss 1.5537 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 021/051 | Loss 1.6251 | Win/lose count 11.0/4.0 (7.0)\n",
            "Epoch 022/051 | Loss 1.6513 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 023/051 | Loss 1.6425 | Win/lose count 9.5/3.0 (6.5)\n",
            "Epoch 024/051 | Loss 1.7215 | Win/lose count 7.0/5.0 (2.0)\n",
            "Epoch 025/051 | Loss 1.6311 | Win/lose count 1.0/3.0 (-2.0)\n",
            "Epoch 026/051 | Loss 1.5847 | Win/lose count 6.5/1.0 (5.5)\n",
            "Epoch 027/051 | Loss 1.6856 | Win/lose count 7.5/3.0 (4.5)\n",
            "Epoch 028/051 | Loss 1.7213 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 029/051 | Loss 1.6854 | Win/lose count 7.5/3.0 (4.5)\n",
            "Epoch 030/051 | Loss 1.6295 | Win/lose count 4.0/0 (4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N4QZ4aNI06PL",
        "colab_type": "code",
        "outputId": "09a75939-f1ca-4cf6-ff0f-d4b8618c5cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('fc_train50.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "8Pcj4WwPvLOT",
        "colab_type": "code",
        "outputId": "42c9b2de-50dc-4335-fc62-6aa65793329f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "s = env.reset()\n",
        "agent.model.predict(s.reshape(1,5,5,2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07330019,  0.08094673,  0.207366  , -0.12013713]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "wvE6KBfC-Y7L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "metadata": {
        "id": "hM1kzFkT-Y7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(16,kernel_size=(3,3), activation = \"relu\"))\n",
        "        model.add(Conv2D(16,kernel_size=(3,3),activation = 'relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4,activation = \"linear\"))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAWT0Skk-Y7O",
        "colab_type": "code",
        "outputId": "3bcafddb-1cc2-4962-b169-46940893b67f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "t1 = time.time()\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "print(\"Duration of training: \", time.time()-t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/051 | Loss 0.1274 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 001/051 | Loss 0.5047 | Win/lose count 0/0 (0)\n",
            "Epoch 002/051 | Loss 2.0511 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 003/051 | Loss 2.0308 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 004/051 | Loss 2.0024 | Win/lose count 5.5/3.0 (2.5)\n",
            "Epoch 005/051 | Loss 1.9885 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 006/051 | Loss 1.9598 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 007/051 | Loss 2.0380 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 008/051 | Loss 1.9802 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 009/051 | Loss 2.0030 | Win/lose count 6.5/4.0 (2.5)\n",
            "Epoch 010/051 | Loss 2.0171 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 011/051 | Loss 1.8415 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 012/051 | Loss 1.9956 | Win/lose count 2.5/1.0 (1.5)\n",
            "Epoch 013/051 | Loss 1.8777 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 014/051 | Loss 1.7633 | Win/lose count 7.0/4.0 (3.0)\n",
            "Epoch 015/051 | Loss 1.8392 | Win/lose count 4.0/1.0 (3.0)\n",
            "Epoch 016/051 | Loss 1.8217 | Win/lose count 9.5/2.0 (7.5)\n",
            "Epoch 017/051 | Loss 1.8530 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 018/051 | Loss 1.7496 | Win/lose count 11.5/0 (11.5)\n",
            "Epoch 019/051 | Loss 1.7941 | Win/lose count 10.5/3.0 (7.5)\n",
            "Epoch 020/051 | Loss 1.7401 | Win/lose count 13.0/2.0 (11.0)\n",
            "Epoch 021/051 | Loss 1.7844 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 022/051 | Loss 1.8553 | Win/lose count 9.0/4.0 (5.0)\n",
            "Epoch 023/051 | Loss 1.8716 | Win/lose count 13.0/6.0 (7.0)\n",
            "Epoch 024/051 | Loss 1.8029 | Win/lose count 8.0/4.0 (4.0)\n",
            "Epoch 025/051 | Loss 1.8844 | Win/lose count 12.0/1.0 (11.0)\n",
            "Epoch 026/051 | Loss 1.8758 | Win/lose count 13.0/4.0 (9.0)\n",
            "Epoch 027/051 | Loss 1.8131 | Win/lose count 11.0/2.0 (9.0)\n",
            "Epoch 028/051 | Loss 1.8174 | Win/lose count 11.5/3.0 (8.5)\n",
            "Epoch 029/051 | Loss 1.9148 | Win/lose count 17.5/3.0 (14.5)\n",
            "Epoch 030/051 | Loss 1.8207 | Win/lose count 11.0/3.0 (8.0)\n",
            "Epoch 031/051 | Loss 1.8073 | Win/lose count 7.5/3.0 (4.5)\n",
            "Epoch 032/051 | Loss 1.8729 | Win/lose count 3.5/1.0 (2.5)\n",
            "Epoch 033/051 | Loss 1.7780 | Win/lose count 13.0/1.0 (12.0)\n",
            "Epoch 034/051 | Loss 1.8490 | Win/lose count 9.5/0 (9.5)\n",
            "Epoch 035/051 | Loss 1.8581 | Win/lose count 19.5/2.0 (17.5)\n",
            "Epoch 036/051 | Loss 1.8698 | Win/lose count 11.5/3.0 (8.5)\n",
            "Epoch 037/051 | Loss 1.8008 | Win/lose count 19.5/6.0 (13.5)\n",
            "Epoch 038/051 | Loss 1.8916 | Win/lose count 9.5/3.0 (6.5)\n",
            "Epoch 039/051 | Loss 1.9440 | Win/lose count 12.0/3.0 (9.0)\n",
            "Epoch 040/051 | Loss 1.9132 | Win/lose count 9.5/3.0 (6.5)\n",
            "Epoch 041/051 | Loss 1.8766 | Win/lose count 19.5/3.0 (16.5)\n",
            "Epoch 042/051 | Loss 1.9357 | Win/lose count 15.0/1.0 (14.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
            "  return umr_maximum(a, axis, None, out, keepdims)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 043/051 | Loss nan | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 044/051 | Loss nan | Win/lose count 2.5/1.0 (1.5)\n",
            "Epoch 045/051 | Loss nan | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 046/051 | Loss nan | Win/lose count 2.0/7.0 (-5.0)\n",
            "Epoch 047/051 | Loss nan | Win/lose count 1.5/4.0 (-2.5)\n",
            "Epoch 048/051 | Loss nan | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 049/051 | Loss nan | Win/lose count 2.0/5.0 (-3.0)\n",
            "Epoch 050/051 | Loss nan | Win/lose count 3.5/1.0 (2.5)\n",
            "Duration of training:  351.31364488601685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cadxOIUN_1G9",
        "colab_type": "code",
        "outputId": "616745c0-03d9-4bfe-f203-4133d5dffccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_train40.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "2Cr3XqNf-Y7P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "metadata": {
        "id": "TwGEEoB_-Y7Q",
        "colab_type": "code",
        "outputId": "517f5adb-9516-4cfa-f599-c3a16c02499a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "cell_type": "code",
      "source": [
        "Temp = 0.6\n",
        "\n",
        "env = Environment(grid_size=size, max_time=T,temperature=Temp)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 12.0/2.0. Average score (10.0)\n",
            "Win/lose count 15.5/3.0. Average score (11.25)\n",
            "Win/lose count 8.0/4.0. Average score (8.833333333333334)\n",
            "Win/lose count 10.5/3.0. Average score (8.5)\n",
            "Win/lose count 11.5/3.0. Average score (8.5)\n",
            "Win/lose count 6.5/2.0. Average score (7.833333333333333)\n",
            "Win/lose count 10.0/2.0. Average score (7.857142857142857)\n",
            "Win/lose count 8.0/2.0. Average score (7.625)\n",
            "Win/lose count 10.0/3.0. Average score (7.555555555555555)\n",
            "Win/lose count 13.5/1.0. Average score (8.05)\n",
            "Final score: 8.05\n",
            "Test of the FC\n",
            "Win/lose count 10.0/4.0. Average score (6.0)\n",
            "Win/lose count 3.0/6.0. Average score (1.5)\n",
            "Win/lose count 3.5/5.0. Average score (0.5)\n",
            "Win/lose count 7.0/6.0. Average score (0.625)\n",
            "Win/lose count 4.5/5.0. Average score (0.4)\n",
            "Win/lose count 17.5/8.0. Average score (1.9166666666666667)\n",
            "Win/lose count 8.0/3.0. Average score (2.357142857142857)\n",
            "Win/lose count 3.0/2.0. Average score (2.1875)\n",
            "Win/lose count 9.0/7.0. Average score (2.1666666666666665)\n",
            "Win/lose count 9.5/7.0. Average score (2.2)\n",
            "Final score: 2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JDw5_9_4-Y7S",
        "colab_type": "code",
        "outputId": "43e299ea-6dc2-4fe2-9f39-b6d013710059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_test3.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "FFUwhLr7-Y7U",
        "colab_type": "code",
        "outputId": "4cbd07d4-5772-4c93-a099-fe262ffc1d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('fc_test1.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "metadata": {
        "id": "ocr3RAsq-Y7W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We observe a lot of loops. Moreover, the agent doesn't take the wisest decisions most of the time. This can be due to the lack of exploration therefore the lack of understanding of some states. Generally, the CNN is more efficient than the fully connected agent."
      ]
    },
    {
      "metadata": {
        "id": "JmI1oZ6B-Y7X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jrRmDeoF-Y7X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    explo = 0.5\n",
        "    \n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        agent.set_epsilon(np.exp(-explo*e))\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "      \n",
        "        \n",
        "        \n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, malusPos, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "            reward += malusPos\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the rat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "        \n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        malusPos = self.malus_position[self.x,self.y]\n",
        "        self.malus_position[self.x,self.y] = min(0.1,self.malus_position(1-)\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, malusPos, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.malus_position[self.x,self.y] = -0.1\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n",
        "    \n",
        "## use those samples of code:\n",
        "#In train explore:\n",
        "#state, reward, game_over = env.act(action, train=True)\n",
        "#\n",
        "### In Environment exploring:\n",
        "## You will have to change n_state to 3 because you will use one more layer!\n",
        "#reward = 0\n",
        "#if train:\n",
        "#    reward = -self.malus_position[self.x, self.y]\n",
        "#self.malus_position[self.x, self.y] = 0.1\n",
        "#\n",
        "#reward = reward + self.board[self.x, self.y]\n",
        "## 3 \"feature\" states instead of 2\n",
        "#state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "#                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "#                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YzuN2aQ-Y7b",
        "colab_type": "code",
        "outputId": "ddb6994e-cb49-41a3-8e86-ff8c25f024c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "epochs_tr =51\n",
        "agent = DQN_CNN(size, lr=0.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
        "t1 = time.time()\n",
        "train_explore(agent, env, epochs_tr, prefix='cnn_train_explore')\n",
        "print(\"Training time: \", time.time()-t1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/051 | Loss 0.0731 | Win/lose count 12.5/9.0 (3.5)\n",
            "Epoch 001/051 | Loss 0.0728 | Win/lose count 10.0/13.0 (-3.0)\n",
            "Epoch 002/051 | Loss 0.0602 | Win/lose count 13.0/6.0 (7.0)\n",
            "Epoch 003/051 | Loss 0.0821 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 004/051 | Loss 0.0744 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 005/051 | Loss 0.0686 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 006/051 | Loss 0.0627 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 007/051 | Loss 0.0348 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 008/051 | Loss 0.0502 | Win/lose count 10.0/2.0 (8.0)\n",
            "Epoch 009/051 | Loss 0.0602 | Win/lose count 7.0/0 (7.0)\n",
            "Epoch 010/051 | Loss 0.0606 | Win/lose count 6.5/1.0 (5.5)\n",
            "Epoch 011/051 | Loss 0.0395 | Win/lose count 2.0/0 (2.0)\n",
            "Epoch 012/051 | Loss 0.0114 | Win/lose count 2.5/1.0 (1.5)\n",
            "Epoch 013/051 | Loss 0.0129 | Win/lose count 9.0/0 (9.0)\n",
            "Epoch 014/051 | Loss 0.0133 | Win/lose count 6.5/0 (6.5)\n",
            "Epoch 015/051 | Loss 0.0243 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 016/051 | Loss 0.0632 | Win/lose count 2.0/0 (2.0)\n",
            "Epoch 017/051 | Loss 0.0476 | Win/lose count 18.0/3.0 (15.0)\n",
            "Epoch 018/051 | Loss 0.0433 | Win/lose count 12.5/0 (12.5)\n",
            "Epoch 019/051 | Loss 0.1026 | Win/lose count 10.0/0 (10.0)\n",
            "Epoch 020/051 | Loss 0.0639 | Win/lose count 16.5/1.0 (15.5)\n",
            "Epoch 021/051 | Loss 0.0834 | Win/lose count 9.5/0 (9.5)\n",
            "Epoch 022/051 | Loss 0.0773 | Win/lose count 6.5/0 (6.5)\n",
            "Epoch 023/051 | Loss 0.1029 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 024/051 | Loss 0.1820 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 025/051 | Loss 0.2928 | Win/lose count 6.5/1.0 (5.5)\n",
            "Epoch 026/051 | Loss 0.3185 | Win/lose count 12.0/0 (12.0)\n",
            "Epoch 027/051 | Loss 0.4562 | Win/lose count 7.5/0 (7.5)\n",
            "Epoch 028/051 | Loss 0.4036 | Win/lose count 11.0/0 (11.0)\n",
            "Epoch 029/051 | Loss 0.4814 | Win/lose count 18.5/0 (18.5)\n",
            "Epoch 030/051 | Loss 0.3579 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 031/051 | Loss 0.3092 | Win/lose count 9.5/0 (9.5)\n",
            "Epoch 032/051 | Loss 0.4815 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 033/051 | Loss 0.4871 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 034/051 | Loss 0.4479 | Win/lose count 4.0/0 (4.0)\n",
            "Epoch 035/051 | Loss 0.4297 | Win/lose count 18.5/0 (18.5)\n",
            "Epoch 036/051 | Loss 0.3232 | Win/lose count 9.0/0 (9.0)\n",
            "Epoch 037/051 | Loss 0.3121 | Win/lose count 9.5/0 (9.5)\n",
            "Epoch 038/051 | Loss 0.3113 | Win/lose count 5.5/0 (5.5)\n",
            "Epoch 039/051 | Loss 0.2500 | Win/lose count 5.0/0 (5.0)\n",
            "Epoch 040/051 | Loss 0.2796 | Win/lose count 9.5/0 (9.5)\n",
            "Epoch 041/051 | Loss 0.4364 | Win/lose count 5.0/0 (5.0)\n",
            "Epoch 042/051 | Loss 0.3522 | Win/lose count 17.5/0 (17.5)\n",
            "Epoch 043/051 | Loss 0.0644 | Win/lose count 15.5/1.0 (14.5)\n",
            "Epoch 044/051 | Loss 0.0653 | Win/lose count 9.0/0 (9.0)\n",
            "Epoch 045/051 | Loss 0.0645 | Win/lose count 7.0/0 (7.0)\n",
            "Epoch 046/051 | Loss 0.0317 | Win/lose count 17.5/2.0 (15.5)\n",
            "Epoch 047/051 | Loss 0.0400 | Win/lose count 0.5/0 (0.5)\n",
            "Epoch 048/051 | Loss 0.0231 | Win/lose count 5.0/1.0 (4.0)\n",
            "Epoch 049/051 | Loss 0.0157 | Win/lose count 10.0/0 (10.0)\n",
            "Epoch 050/051 | Loss 0.0196 | Win/lose count 8.0/0 (8.0)\n",
            "Training time:  370.61648654937744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gIMNpIn3oC-R",
        "colab_type": "code",
        "outputId": "dfcc9f3f-a578-44ab-a81d-525f1c664ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_train_explore50.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "tQd2yilK-Y7e",
        "colab_type": "code",
        "outputId": "2f9a6d2b-9a92-465e-a63f-232c936eaec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "def test_explore(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    \n",
        "        \n",
        "    for e in range(epochs):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "    \n",
        "        win = 0\n",
        "        lose = 0\n",
        "    \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "    \n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward,malusPos, game_over = env.act(action)\n",
        "    \n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"{}, Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(e,win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))\n",
        "test_explore(agent,env,epochs_test,prefix='cnn_test_explore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 5.5/0. Average score (5.5)\n",
            "Win/lose count 7.5/0. Average score (6.5)\n",
            "Win/lose count 4.0/0. Average score (5.666666666666667)\n",
            "Win/lose count 4.5/0. Average score (5.375)\n",
            "Win/lose count 1.5/0. Average score (4.6)\n",
            "Win/lose count 4.0/0. Average score (4.5)\n",
            "Win/lose count 13.0/0. Average score (5.714285714285714)\n",
            "Win/lose count 15.0/0. Average score (6.875)\n",
            "Win/lose count 18.0/1.0. Average score (8.0)\n",
            "Win/lose count 6.5/0. Average score (7.85)\n",
            "Final score: 7.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dHg6kyMPp3Jz",
        "colab_type": "code",
        "outputId": "576f66e6-fce8-44de-d056-c139e619d028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_test_explore7.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "t11_OuSH-Y7g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "metadata": {
        "id": "KW7ylcbo-Y7h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "xw_8qail-Y7h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***"
      ]
    }
  ]
}